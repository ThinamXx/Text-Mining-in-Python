{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Introduction to NLTK\n",
    "\n",
    "In part 1 of this assignment you will use nltk to explore the Herman Melville novel Moby Dick. Then in part 2 you will create a spelling recommender function that uses nltk to find words similar to the misspelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Analyzing Moby Dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# If you would like to work with the raw text you can use 'moby_raw'\n",
    "with open('moby.txt', 'r') as f:\n",
    "    moby_raw = f.read()\n",
    "    \n",
    "# If you would like to work with the novel in nltk.Text format you can use 'text1'\n",
    "nltk.download(\"punkt\")\n",
    "moby_tokens = nltk.word_tokenize(moby_raw)\n",
    "text1 = nltk.Text(moby_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "How many tokens (words and punctuation symbols) are in text1?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254989"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_one():\n",
    "    \n",
    "    return len(nltk.word_tokenize(moby_raw)) # or alternatively len(text1)\n",
    "\n",
    "example_one()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "How many unique tokens (unique words and punctuation) does text1 have?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20755"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_two():\n",
    "    \n",
    "    return len(set(nltk.word_tokenize(moby_raw))) # or alternatively len(set(text1))\n",
    "\n",
    "example_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "\n",
    "After lemmatizing the verbs, how many unique tokens does text1 have?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16900"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "def example_three():\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(w,'v') for w in text1]\n",
    "\n",
    "    return len(set(lemmatized))\n",
    "\n",
    "example_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the lexical diversity of the given text input? (i.e. ratio of unique tokens to the total number of tokens)\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08139566804842562"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_one():\n",
    "    \n",
    "    return example_two()/example_one()\n",
    "\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What percentage of tokens is 'whale'or 'Whale'?\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004125668166077752"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_two():\n",
    "    tokens = []\n",
    "    for token in text1:\n",
    "        if (token == \"whale\") | (token == \"Whale\"):\n",
    "            tokens.append(token)\n",
    "    \n",
    "    \n",
    "    return (len(tokens) / len(text1))\n",
    "\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4125668166077752"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_two():\n",
    "    return ((text1.vocab()[\"whale\"] + text1.vocab()[\"Whale\"])/ len(text1))*100\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What are the 20 most frequently occurring (unique) tokens in the text? What is their frequency?\n",
    "\n",
    "*This function should return a list of 20 tuples where each tuple is of the form `(token, frequency)`. The list should be sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 19204),\n",
       " ('the', 13715),\n",
       " ('.', 7308),\n",
       " ('of', 6513),\n",
       " ('and', 6010),\n",
       " ('a', 4545),\n",
       " ('to', 4515),\n",
       " (';', 4173),\n",
       " ('in', 3908),\n",
       " ('that', 2978),\n",
       " ('his', 2459),\n",
       " ('it', 2196),\n",
       " ('I', 2097),\n",
       " ('!', 1767),\n",
       " ('is', 1722),\n",
       " ('--', 1713),\n",
       " ('with', 1659),\n",
       " ('he', 1658),\n",
       " ('was', 1639),\n",
       " ('as', 1620)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "def answer_three():\n",
    "    frequencies = FreqDist(moby_tokens)\n",
    "    \n",
    "    \n",
    "    return frequencies.most_common(20)\n",
    "\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 19204),\n",
       " ('the', 13715),\n",
       " ('.', 7308),\n",
       " ('of', 6513),\n",
       " ('and', 6010),\n",
       " ('a', 4545),\n",
       " ('to', 4515),\n",
       " (';', 4173),\n",
       " ('in', 3908),\n",
       " ('that', 2978),\n",
       " ('his', 2459),\n",
       " ('it', 2196),\n",
       " ('I', 2097),\n",
       " ('!', 1767),\n",
       " ('is', 1722),\n",
       " ('--', 1713),\n",
       " ('with', 1659),\n",
       " ('he', 1658),\n",
       " ('was', 1639),\n",
       " ('as', 1620)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_three():\n",
    "    import operator\n",
    "    \n",
    "    return sorted(text1.vocab().items(), key=operator.itemgetter(1), reverse=True)[:20]\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "What tokens have a length of greater than 5 and frequency of more than 150?\n",
    "\n",
    "*This function should return an alphabetically sorted list of the tokens that match the above constraints. To sort your list, use `sorted()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Captain',\n",
       " 'Pequod',\n",
       " 'Queequeg',\n",
       " 'Starbuck',\n",
       " 'almost',\n",
       " 'before',\n",
       " 'himself',\n",
       " 'little',\n",
       " 'seemed',\n",
       " 'should',\n",
       " 'though',\n",
       " 'through',\n",
       " 'whales',\n",
       " 'without']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies = FreqDist(moby_tokens)\n",
    "df = pd.DataFrame(frequencies.most_common(), columns=[\"token\", \"frequency\"])\n",
    "def answer_four():\n",
    "    result = df[(df[\"frequency\"] > 150) & (df[\"token\"].str.len() > 5)]\n",
    "    \n",
    "    return sorted(result.token)\n",
    "\n",
    "answer_four()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Captain',\n",
       " 'Pequod',\n",
       " 'Queequeg',\n",
       " 'Starbuck',\n",
       " 'almost',\n",
       " 'before',\n",
       " 'himself',\n",
       " 'little',\n",
       " 'seemed',\n",
       " 'should',\n",
       " 'though',\n",
       " 'through',\n",
       " 'whales',\n",
       " 'without'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies = FreqDist(text1)\n",
    "def answer_four():\n",
    "    tokens = []\n",
    "    for token in text1:\n",
    "        if (len(token) > 5) & (frequencies[token] > 150):\n",
    "            tokens.append(token)\n",
    "            \n",
    "    return set(sorted(tokens))\n",
    "answer_four()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Captain',\n",
       " 'Pequod',\n",
       " 'Queequeg',\n",
       " 'Starbuck',\n",
       " 'almost',\n",
       " 'before',\n",
       " 'himself',\n",
       " 'little',\n",
       " 'seemed',\n",
       " 'should',\n",
       " 'though',\n",
       " 'through',\n",
       " 'whales',\n",
       " 'without']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_four():\n",
    "    return sorted([token for token, freq in text1.vocab().items() if len(token) > 5 and freq > 150])\n",
    "answer_four()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Find the longest word in text1 and that word's length.\n",
    "\n",
    "*This function should return a tuple `(longest_word, length)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"twelve-o'clock-at-night\", 23)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_five():\n",
    "    frequencies = FreqDist(moby_tokens)\n",
    "    df = pd.DataFrame(frequencies.most_common(), columns=[\"token\", \"frequency\"])\n",
    "    df[\"length\"] = df[\"token\"].str.len()\n",
    "    df = df.sort_values([\"length\"], ascending=False)\n",
    "    df1 = df.iloc[0]\n",
    "    result = (df1[\"token\"], df1[\"length\"])\n",
    "    return result\n",
    "\n",
    "answer_five()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"twelve-o'clock-at-night\", 23)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively\n",
    "def answer_five():\n",
    "    frequencies = FreqDist(moby_tokens)\n",
    "    df = pd.DataFrame(frequencies.most_common(), columns=[\"token\", \"frequency\"])\n",
    "    length = max(df.token.str.len())\n",
    "    longest = df.token.str.extractall(\"(?P<long>.{{{}}})\".format(length))\n",
    "    return (longest.long.iloc[0], length)\n",
    "answer_five()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"twelve-o'clock-at-night\", 23)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_five():\n",
    "    import operator\n",
    "    return sorted([(token, len(token))for token, freq in text1.vocab().items()], key=operator.itemgetter(1), reverse=True)[0]\n",
    "answer_five()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "What unique words have a frequency of more than 2000? What is their frequency?\n",
    "\n",
    "\"Hint:  you may want to use `isalpha()` to check if the token is a word and not punctuation.\"\n",
    "\n",
    "*This function should return a list of tuples of the form `(frequency, word)` sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13715, 'the'),\n",
       " (6513, 'of'),\n",
       " (6010, 'and'),\n",
       " (4545, 'a'),\n",
       " (4515, 'to'),\n",
       " (3908, 'in'),\n",
       " (2978, 'that'),\n",
       " (2459, 'his'),\n",
       " (2196, 'it'),\n",
       " (2097, 'I'),\n",
       " (1722, 'is'),\n",
       " (1659, 'with'),\n",
       " (1658, 'he'),\n",
       " (1639, 'was'),\n",
       " (1620, 'as'),\n",
       " (1444, 'all'),\n",
       " (1413, 'for'),\n",
       " (1280, 'this'),\n",
       " (1230, 'at'),\n",
       " (1170, 'not'),\n",
       " (1135, 'by'),\n",
       " (1110, 'but'),\n",
       " (1058, 'him'),\n",
       " (1052, 'from'),\n",
       " (1027, 'be'),\n",
       " (1003, 'on'),\n",
       " (914, 'so'),\n",
       " (880, 'one'),\n",
       " (841, 'you'),\n",
       " (782, 'whale'),\n",
       " (767, 'had'),\n",
       " (763, 'have'),\n",
       " (710, 'there'),\n",
       " (703, 'But'),\n",
       " (697, 'or'),\n",
       " (679, 'were'),\n",
       " (645, 'now'),\n",
       " (640, 'which'),\n",
       " (624, 'me'),\n",
       " (612, 'their'),\n",
       " (603, 'The'),\n",
       " (586, 'are'),\n",
       " (586, 'they'),\n",
       " (582, 'an'),\n",
       " (578, 'some'),\n",
       " (570, 'then'),\n",
       " (564, 'my'),\n",
       " (558, 'like'),\n",
       " (553, 'when'),\n",
       " (537, 'upon'),\n",
       " (519, 'into'),\n",
       " (518, 'out'),\n",
       " (500, 'more'),\n",
       " (499, 'up'),\n",
       " (498, 'Ahab'),\n",
       " (483, 'no'),\n",
       " (472, 'man'),\n",
       " (471, 'them'),\n",
       " (454, 'ship'),\n",
       " (438, 'what'),\n",
       " (429, 'old'),\n",
       " (427, 'ye'),\n",
       " (425, 'would'),\n",
       " (421, 'if'),\n",
       " (415, 'been'),\n",
       " (411, 'we'),\n",
       " (409, 'other'),\n",
       " (397, 'over'),\n",
       " (381, 'these'),\n",
       " (377, 'will'),\n",
       " (372, 'its'),\n",
       " (367, 'And'),\n",
       " (365, 'sea'),\n",
       " (363, 'do'),\n",
       " (360, 'only'),\n",
       " (355, 'down'),\n",
       " (336, 'such'),\n",
       " (335, 'though'),\n",
       " (329, 'her'),\n",
       " (320, 'any'),\n",
       " (318, 'who'),\n",
       " (316, 'time'),\n",
       " (311, 'very'),\n",
       " (309, 'than'),\n",
       " (308, 'It'),\n",
       " (305, 'long'),\n",
       " (304, 'about'),\n",
       " (302, 'said'),\n",
       " (299, 'still'),\n",
       " (299, 'yet'),\n",
       " (297, 'those'),\n",
       " (293, 'before'),\n",
       " (291, 'has'),\n",
       " (290, 'great'),\n",
       " (283, 'must'),\n",
       " (283, 'seemed'),\n",
       " (281, 'boat'),\n",
       " (276, 'most'),\n",
       " (275, 'two'),\n",
       " (275, 'last'),\n",
       " (270, 'here'),\n",
       " (270, 'head'),\n",
       " (270, 'Whale'),\n",
       " (264, 'did'),\n",
       " (262, 'way'),\n",
       " (256, 'can'),\n",
       " (252, 'again'),\n",
       " (252, 'Queequeg'),\n",
       " (252, 'Stubb'),\n",
       " (250, 'see'),\n",
       " (247, 'after'),\n",
       " (247, 'little'),\n",
       " (240, 'your'),\n",
       " (240, 'round'),\n",
       " (236, 'whales'),\n",
       " (235, 'say'),\n",
       " (235, 'In'),\n",
       " (231, 'thou'),\n",
       " (231, 'men'),\n",
       " (231, 'three'),\n",
       " (229, 'may'),\n",
       " (228, 'us'),\n",
       " (227, 'He'),\n",
       " (226, 'through'),\n",
       " (222, 'every'),\n",
       " (221, 'could'),\n",
       " (219, 'being'),\n",
       " (218, 'much'),\n",
       " (216, 'while'),\n",
       " (213, 'Captain'),\n",
       " (210, 'off'),\n",
       " (210, 'first'),\n",
       " (210, 'same'),\n",
       " (205, 'own'),\n",
       " (203, 'himself'),\n",
       " (198, 'our'),\n",
       " (197, 'For'),\n",
       " (195, 'never'),\n",
       " (194, 'hand'),\n",
       " (193, 'Starbuck'),\n",
       " (190, 'ever'),\n",
       " (189, 'side'),\n",
       " (188, 'thing'),\n",
       " (188, 'where'),\n",
       " (187, 'how'),\n",
       " (186, 'almost'),\n",
       " (183, 'might'),\n",
       " (182, 'too'),\n",
       " (180, 'go'),\n",
       " (180, 'should'),\n",
       " (179, 'even'),\n",
       " (178, 'good'),\n",
       " (177, 'made'),\n",
       " (172, 'away'),\n",
       " (166, 'world'),\n",
       " (166, 'well'),\n",
       " (166, 'water'),\n",
       " (164, 'Pequod'),\n",
       " (163, 'What'),\n",
       " (161, 'many'),\n",
       " (160, 'seen'),\n",
       " (159, 'deck'),\n",
       " (158, 'among'),\n",
       " (158, 'white'),\n",
       " (157, 'day'),\n",
       " (155, 'eyes'),\n",
       " (155, 'far'),\n",
       " (155, 'cried'),\n",
       " (154, 'without'),\n",
       " (152, 'sort'),\n",
       " (150, 'come'),\n",
       " (150, 'CHAPTER'),\n",
       " (149, 'A'),\n",
       " (149, 'know'),\n",
       " (148, 'thought'),\n",
       " (148, 'part'),\n",
       " (146, 'back'),\n",
       " (145, 'So'),\n",
       " (144, 'There'),\n",
       " (144, 'once'),\n",
       " (143, 'sir'),\n",
       " (142, 'boats'),\n",
       " (139, 'Now'),\n",
       " (139, 'crew'),\n",
       " (138, 'air'),\n",
       " (136, 'whole'),\n",
       " (135, 'life'),\n",
       " (134, 'look'),\n",
       " (133, 'Sperm'),\n",
       " (132, 'against'),\n",
       " (132, 'things'),\n",
       " (130, 'came'),\n",
       " (130, 'night'),\n",
       " (129, 'thee'),\n",
       " (129, 'God'),\n",
       " (127, 'each'),\n",
       " (125, 'feet'),\n",
       " (122, 'hands'),\n",
       " (121, 'small'),\n",
       " (120, 'As'),\n",
       " (120, 'till'),\n",
       " (119, 'something'),\n",
       " (118, 'take'),\n",
       " (118, 'let'),\n",
       " (118, 'tell'),\n",
       " (118, 'both'),\n",
       " (117, 'Oh'),\n",
       " (117, 'between'),\n",
       " (115, 'found'),\n",
       " (115, 'under'),\n",
       " (113, 'called'),\n",
       " (113, 'soon'),\n",
       " (111, 'full'),\n",
       " (111, 'saw'),\n",
       " (111, 'place'),\n",
       " (111, 'times'),\n",
       " (110, 'body'),\n",
       " (110, 'just'),\n",
       " (110, 'along'),\n",
       " (109, 'think'),\n",
       " (109, 'make'),\n",
       " (109, 'captain'),\n",
       " (109, 'heard'),\n",
       " (108, 'line'),\n",
       " (107, 'towards'),\n",
       " (107, 'thus'),\n",
       " (106, 'another'),\n",
       " (105, 'moment'),\n",
       " (105, 'thy'),\n",
       " (104, 'This'),\n",
       " (104, 'poor'),\n",
       " (104, 'sight'),\n",
       " (104, 'Flask'),\n",
       " (103, 'fish'),\n",
       " (103, 'she'),\n",
       " (102, 'nothing'),\n",
       " (102, 'sperm'),\n",
       " (99, 'whaling'),\n",
       " (98, 'THE'),\n",
       " (97, 'went'),\n",
       " (96, 'No'),\n",
       " (95, 'strange'),\n",
       " (95, 'end'),\n",
       " (94, 'face'),\n",
       " (93, 'high'),\n",
       " (92, 'few'),\n",
       " (92, 'get'),\n",
       " (91, 'voyage'),\n",
       " (91, 'does'),\n",
       " (91, 'sun'),\n",
       " (90, 'dead'),\n",
       " (89, 'years'),\n",
       " (89, 'right'),\n",
       " (89, 'half'),\n",
       " (89, 'stood'),\n",
       " (89, 'White'),\n",
       " (88, 'also'),\n",
       " (87, 'heart'),\n",
       " (87, 'certain'),\n",
       " (86, 'whose'),\n",
       " (86, 'hold'),\n",
       " (85, 'matter'),\n",
       " (85, 'leg'),\n",
       " (84, 'am'),\n",
       " (84, 'shall'),\n",
       " (84, 'That'),\n",
       " (84, 'seems'),\n",
       " (84, 'arm'),\n",
       " (84, 'Nantucket'),\n",
       " (84, 'itself'),\n",
       " (84, 'seem'),\n",
       " (84, 'At'),\n",
       " (83, 'Jonah'),\n",
       " (83, 'Aye'),\n",
       " (82, 'Moby'),\n",
       " (82, 'Dick'),\n",
       " (82, 'eye'),\n",
       " (82, 'perhaps'),\n",
       " (82, 'soul'),\n",
       " (82, 'indeed'),\n",
       " (81, 'sometimes'),\n",
       " (80, 'known'),\n",
       " (80, 'however'),\n",
       " (80, 'seas'),\n",
       " (80, 'always'),\n",
       " (80, 'wild'),\n",
       " (79, 'sail'),\n",
       " (79, 'going'),\n",
       " (79, 'nor'),\n",
       " (79, 'black'),\n",
       " (79, 'present'),\n",
       " (78, 'within'),\n",
       " (78, 'length'),\n",
       " (78, 'They'),\n",
       " (78, 'oil'),\n",
       " (78, 'mind'),\n",
       " (77, 'ships'),\n",
       " (77, 'days'),\n",
       " (77, 'stand'),\n",
       " (77, 'instant'),\n",
       " (76, 'word'),\n",
       " (76, 'whether'),\n",
       " (76, 'large'),\n",
       " (76, 'hard'),\n",
       " (76, 'Bildad'),\n",
       " (75, 'least'),\n",
       " (75, 'tail'),\n",
       " (75, 'young'),\n",
       " (75, 'iron'),\n",
       " (74, 'beneath'),\n",
       " (74, 'enough'),\n",
       " (74, 'Nor'),\n",
       " (74, 'done'),\n",
       " (74, 'Peleg'),\n",
       " (73, 'true'),\n",
       " (73, 'land'),\n",
       " (73, 'vast'),\n",
       " (73, 'living'),\n",
       " (73, 'set'),\n",
       " (73, 'harpooneer'),\n",
       " (73, 'because'),\n",
       " (73, 'light'),\n",
       " (73, 'standing'),\n",
       " (72, 'put'),\n",
       " (72, 'harpoon'),\n",
       " (72, 'bed'),\n",
       " (71, 'give'),\n",
       " (71, 'why'),\n",
       " (71, 'cabin'),\n",
       " (69, 'near'),\n",
       " (68, 'name'),\n",
       " (68, 'four'),\n",
       " (68, 'open'),\n",
       " (68, 'myself'),\n",
       " (68, 'whalemen'),\n",
       " (68, 'mate'),\n",
       " (68, 'rather'),\n",
       " (68, 'morning'),\n",
       " (68, 'often'),\n",
       " (68, 'aye'),\n",
       " (67, 'case'),\n",
       " (67, 'lay'),\n",
       " (66, 'wind'),\n",
       " (66, 'point'),\n",
       " (66, 'left'),\n",
       " (66, 'business'),\n",
       " (66, 'ere'),\n",
       " (66, 'turned'),\n",
       " (66, 'keep'),\n",
       " (66, 'waters'),\n",
       " (66, 'Pip'),\n",
       " (65, 'deep'),\n",
       " (65, 'fire'),\n",
       " (65, 'How'),\n",
       " (64, 'Leviathan'),\n",
       " (64, 'together'),\n",
       " (64, 'order'),\n",
       " (64, 'general'),\n",
       " (64, 'reason'),\n",
       " (64, 'looked'),\n",
       " (63, 'ocean'),\n",
       " (63, 'since'),\n",
       " (62, 'best'),\n",
       " (62, 'board'),\n",
       " (62, 'having'),\n",
       " (61, 'To'),\n",
       " (60, 'hear'),\n",
       " (60, 'If'),\n",
       " (60, 'death'),\n",
       " (60, 'better'),\n",
       " (59, 'themselves'),\n",
       " (59, 'further'),\n",
       " (59, 'live'),\n",
       " (58, 'gone'),\n",
       " (58, 'mouth'),\n",
       " (58, 'work'),\n",
       " (58, 'With'),\n",
       " (57, 'lower'),\n",
       " (56, 'feel'),\n",
       " (56, 'peculiar'),\n",
       " (56, 'home'),\n",
       " (56, 'fine'),\n",
       " (56, 'chase'),\n",
       " (56, 'dark'),\n",
       " (56, 'therefore'),\n",
       " (55, 'find'),\n",
       " (55, 'Indian'),\n",
       " (55, 'harpooneers'),\n",
       " (55, 'looking'),\n",
       " (55, 'Then'),\n",
       " (55, 'All'),\n",
       " (55, 'entire'),\n",
       " (54, 'goes'),\n",
       " (54, 'above'),\n",
       " (54, 'turn'),\n",
       " (54, 'jaw'),\n",
       " (54, 'short'),\n",
       " (54, 'Well'),\n",
       " (54, 'second'),\n",
       " (54, 'His'),\n",
       " (54, 'Tashtego'),\n",
       " (53, 'aloft'),\n",
       " (53, 'began'),\n",
       " (53, 'curious'),\n",
       " (52, 'craft'),\n",
       " (52, 'forth'),\n",
       " (52, 'savage'),\n",
       " (52, 'bottom'),\n",
       " (52, 'When'),\n",
       " (52, 'comes'),\n",
       " (52, 'call'),\n",
       " (51, 'By'),\n",
       " (51, 'close'),\n",
       " (51, 'run'),\n",
       " (51, 'blood'),\n",
       " (51, 'less'),\n",
       " (51, 'turning'),\n",
       " (51, 'broad'),\n",
       " (51, 'fishery'),\n",
       " (50, 'vessel'),\n",
       " (50, 'behind'),\n",
       " (50, 'taken'),\n",
       " (50, 'hundred'),\n",
       " (50, 'Right'),\n",
       " (50, 'thousand'),\n",
       " (50, 'taking'),\n",
       " (50, 'sailors'),\n",
       " (50, 'rest'),\n",
       " (49, 'coming'),\n",
       " (49, 'OF'),\n",
       " (49, 'sharks'),\n",
       " (49, 'particular'),\n",
       " (49, 'took'),\n",
       " (49, 'ivory'),\n",
       " (48, 'devil'),\n",
       " (48, 'Here'),\n",
       " (48, 'waves'),\n",
       " (48, 'Look'),\n",
       " (48, 'used'),\n",
       " (48, 'bows'),\n",
       " (47, 'mighty'),\n",
       " (47, 'Not'),\n",
       " (47, 'Do'),\n",
       " (47, 'slowly'),\n",
       " (47, 'story'),\n",
       " (47, 'New'),\n",
       " (47, 'Though'),\n",
       " (47, 'common'),\n",
       " (47, 'kept'),\n",
       " (47, 'stranger'),\n",
       " (46, 'earth'),\n",
       " (46, 'view'),\n",
       " (46, 'stern'),\n",
       " (46, 'cut'),\n",
       " (46, 'voice'),\n",
       " (46, 'speak'),\n",
       " (46, 'green'),\n",
       " (46, 'fellow'),\n",
       " (46, 'English'),\n",
       " (46, 'forward'),\n",
       " (46, 'On'),\n",
       " (46, 'Yes'),\n",
       " (46, 'sailor'),\n",
       " (46, 'else'),\n",
       " (46, 'broken'),\n",
       " (46, 'mark'),\n",
       " (46, 'got'),\n",
       " (46, 'next'),\n",
       " (46, 'several'),\n",
       " (46, 'below'),\n",
       " (46, 'spout'),\n",
       " (45, 'touching'),\n",
       " (45, 'monster'),\n",
       " (45, 'bones'),\n",
       " (45, 'lost'),\n",
       " (45, 'sat'),\n",
       " (45, 'struck'),\n",
       " (45, 'Yet'),\n",
       " (45, 'ten'),\n",
       " (45, 'Why'),\n",
       " (45, 'suddenly'),\n",
       " (45, 'fact'),\n",
       " (45, 'fast'),\n",
       " (44, 'queer'),\n",
       " (44, 'whatever'),\n",
       " (44, 'Lord'),\n",
       " (44, 'teeth'),\n",
       " (44, 'noble'),\n",
       " (44, 'chance'),\n",
       " (44, 'We'),\n",
       " (44, 'told'),\n",
       " (44, 'caught'),\n",
       " (44, 'form'),\n",
       " (44, 'wide'),\n",
       " (44, 'sure'),\n",
       " (44, 'rope'),\n",
       " (44, 'especially'),\n",
       " (44, 'straight'),\n",
       " (44, 'sleep'),\n",
       " (44, 'says'),\n",
       " (44, 'mine'),\n",
       " (44, 'You'),\n",
       " (44, 'room'),\n",
       " (44, 'means'),\n",
       " (43, 'somehow'),\n",
       " (43, 'whom'),\n",
       " (43, 'knew'),\n",
       " (43, 'nigh'),\n",
       " (43, 'rolled'),\n",
       " (43, 'heads'),\n",
       " (43, 'whaleman'),\n",
       " (42, 'mere'),\n",
       " (42, 'making'),\n",
       " (42, 'people'),\n",
       " (42, 'hours'),\n",
       " (42, 'grand'),\n",
       " (42, 'watch'),\n",
       " (42, 'door'),\n",
       " (42, 'seamen'),\n",
       " (42, 'running'),\n",
       " (42, 'sudden'),\n",
       " (42, 'creature'),\n",
       " (42, 'surface'),\n",
       " (41, 'calm'),\n",
       " (41, 'lance'),\n",
       " (41, 'blue'),\n",
       " (41, 'quite'),\n",
       " (41, 'cook'),\n",
       " (41, 'anything'),\n",
       " (41, 'passed'),\n",
       " (41, 'parts'),\n",
       " (41, 'sharp'),\n",
       " (41, 'felt'),\n",
       " (41, 'course'),\n",
       " (41, 'sound'),\n",
       " (41, 'wondrous'),\n",
       " (40, 'wake'),\n",
       " (40, 'Who'),\n",
       " (40, 'saying'),\n",
       " (40, 'brow'),\n",
       " (40, 'Steelkilt'),\n",
       " (39, 'clear'),\n",
       " (39, 'art'),\n",
       " (39, 'plainly'),\n",
       " (39, 'either'),\n",
       " (39, 'distance'),\n",
       " (39, 'bow'),\n",
       " (39, 'object'),\n",
       " (39, 'mass'),\n",
       " (39, 'mortal'),\n",
       " (39, 'boy'),\n",
       " (39, 'purpose'),\n",
       " (39, 'hour'),\n",
       " (39, 'mates'),\n",
       " (39, 'makes'),\n",
       " (38, 'leaving'),\n",
       " (38, 'brought'),\n",
       " (38, 'Some'),\n",
       " (38, 'single'),\n",
       " (38, 'sailed'),\n",
       " (38, 'cry'),\n",
       " (38, 'darted'),\n",
       " (38, 'concerning'),\n",
       " (38, 'gave'),\n",
       " (37, 'others'),\n",
       " (37, 'alone'),\n",
       " (37, 'Thou'),\n",
       " (37, 'Let'),\n",
       " (37, 'AND'),\n",
       " (37, 'fixed'),\n",
       " (37, 'heaven'),\n",
       " (37, 'manner'),\n",
       " (37, 'mean'),\n",
       " (37, 'plain'),\n",
       " (37, 'five'),\n",
       " (37, 'help'),\n",
       " (37, 'held'),\n",
       " (37, 'hat'),\n",
       " (37, 'power'),\n",
       " (37, 'gentlemen'),\n",
       " (37, 'pull'),\n",
       " (36, 'placed'),\n",
       " (36, 'ago'),\n",
       " (36, 'around'),\n",
       " (36, 'fell'),\n",
       " (36, 'new'),\n",
       " (36, 'bulwarks'),\n",
       " (36, 'easy'),\n",
       " (36, 'various'),\n",
       " (36, 'bone'),\n",
       " (36, 'forehead'),\n",
       " (36, 'ready'),\n",
       " (36, 'unknown'),\n",
       " (36, 'flukes'),\n",
       " (36, 'aspect'),\n",
       " (36, 'oh'),\n",
       " (36, 'use'),\n",
       " (36, 'sails'),\n",
       " (36, 'given'),\n",
       " (36, 'ground'),\n",
       " (36, 'carpenter'),\n",
       " (36, 'oars'),\n",
       " (35, 'book'),\n",
       " (35, 'coast'),\n",
       " (35, 'Greenland'),\n",
       " (35, 'legs'),\n",
       " (35, 'famous'),\n",
       " (35, 'sign'),\n",
       " (35, 'suppose'),\n",
       " (35, 'human'),\n",
       " (35, 'gold'),\n",
       " (34, 'brain'),\n",
       " (34, 'WHALE'),\n",
       " (34, 'nature'),\n",
       " (34, 'pipe'),\n",
       " (34, 'American'),\n",
       " (34, 'shot'),\n",
       " (34, 'previous'),\n",
       " (34, 'forecastle'),\n",
       " (34, 'Such'),\n",
       " (34, 'Cape'),\n",
       " (34, 'middle'),\n",
       " (34, 'holding'),\n",
       " (34, 'thoughts'),\n",
       " (34, 'mad'),\n",
       " (34, 'heavy'),\n",
       " (34, 'arms'),\n",
       " (34, 'turns'),\n",
       " (34, 'remained'),\n",
       " (34, 'Daggoo'),\n",
       " (33, 'strong'),\n",
       " (33, 'fifty'),\n",
       " (33, 'killed'),\n",
       " (33, 'creatures'),\n",
       " (33, 'ashore'),\n",
       " (33, 'nearly'),\n",
       " (33, 'boys'),\n",
       " (33, 'idea'),\n",
       " (33, 'house'),\n",
       " (33, 'company'),\n",
       " (33, 'hammock'),\n",
       " (33, 'none'),\n",
       " (33, 'completely'),\n",
       " (33, 'top'),\n",
       " (33, 'skeleton'),\n",
       " (33, 'sailing'),\n",
       " (32, 'rolling'),\n",
       " (32, 'bulk'),\n",
       " (32, 'doubt'),\n",
       " (32, 'fear'),\n",
       " (32, 'passage'),\n",
       " (32, 'Pacific'),\n",
       " (32, 'coffin'),\n",
       " (32, 'account'),\n",
       " (32, 'rigging'),\n",
       " (32, 'bear'),\n",
       " (32, 'low'),\n",
       " (32, 'lines'),\n",
       " (32, 'table'),\n",
       " (32, 'want'),\n",
       " (32, 'wonder'),\n",
       " (32, 'skin'),\n",
       " (32, 'drawing'),\n",
       " (32, 'show'),\n",
       " (32, 'proper'),\n",
       " (32, 'intervals'),\n",
       " (32, 'SAILOR'),\n",
       " (31, 'miles'),\n",
       " (31, 'species'),\n",
       " (31, 'quick'),\n",
       " (31, 'darkness'),\n",
       " (31, 'red'),\n",
       " (31, 'jet'),\n",
       " (31, 'leviathan'),\n",
       " (31, 'visible'),\n",
       " (31, 'planks'),\n",
       " (31, 'weather'),\n",
       " (31, 'hardly'),\n",
       " (31, 'substance'),\n",
       " (31, 'helm'),\n",
       " (31, 'across'),\n",
       " (31, 'aft'),\n",
       " (31, 'nose'),\n",
       " (31, 'except'),\n",
       " (31, 'natural'),\n",
       " (30, 'While'),\n",
       " (30, 'generally'),\n",
       " (30, 'fresh'),\n",
       " (30, 'possible'),\n",
       " (30, 'upper'),\n",
       " (30, 'Besides'),\n",
       " (30, 'act'),\n",
       " (30, 'really'),\n",
       " (30, 'fair'),\n",
       " (30, 'soft'),\n",
       " (30, 'truth'),\n",
       " (30, 'sky'),\n",
       " (30, 'carried'),\n",
       " (30, 'cast'),\n",
       " (30, 'die'),\n",
       " (30, 'hull'),\n",
       " (30, 'instances'),\n",
       " (29, 'altogether'),\n",
       " (29, 'Whales'),\n",
       " (29, 'swimming'),\n",
       " (29, 'huge'),\n",
       " (29, 'jaws'),\n",
       " (29, 'steel'),\n",
       " (29, 'entirely'),\n",
       " (29, 'late'),\n",
       " (29, 'possibly'),\n",
       " (29, 'smoke'),\n",
       " (29, 'vain'),\n",
       " (29, 'unless'),\n",
       " (29, 'mast'),\n",
       " (29, 'cold'),\n",
       " (29, 'foot'),\n",
       " (29, 'tossed'),\n",
       " (29, 'final'),\n",
       " (29, 'harpoons'),\n",
       " (29, 'stands'),\n",
       " (29, 'mariners'),\n",
       " (29, 'touch'),\n",
       " (29, 'wood'),\n",
       " (29, 'question'),\n",
       " (29, 'pass'),\n",
       " (29, 'strangely'),\n",
       " (29, 'hammer'),\n",
       " (29, 'rising'),\n",
       " (29, 'de'),\n",
       " (29, 'hoisted'),\n",
       " (28, 'ancient'),\n",
       " (28, 'strike'),\n",
       " (28, 'One'),\n",
       " (28, 'try'),\n",
       " (28, 'fishermen'),\n",
       " (28, 'free'),\n",
       " (28, 'Sir'),\n",
       " (28, 'pretty'),\n",
       " (28, 'knows'),\n",
       " (28, 'mild'),\n",
       " (28, 'considering'),\n",
       " (28, 'astern'),\n",
       " (28, 'already'),\n",
       " (28, 'words'),\n",
       " (28, 'hung'),\n",
       " (28, 'become'),\n",
       " (28, 'feeling'),\n",
       " (28, 'third'),\n",
       " (28, 'glance'),\n",
       " (28, 'O'),\n",
       " (28, 'start'),\n",
       " (28, 'leeward'),\n",
       " (28, 'Parsee'),\n",
       " (27, 'hearts'),\n",
       " (27, 'sides'),\n",
       " (27, 'kind'),\n",
       " (27, 'Where'),\n",
       " (27, 'gale'),\n",
       " (27, 'precisely'),\n",
       " (27, 'landlord'),\n",
       " (27, 'somewhat'),\n",
       " (27, 'certainly'),\n",
       " (27, 'seeing'),\n",
       " (27, 'person'),\n",
       " (27, 'Come'),\n",
       " (27, 'wo'),\n",
       " (27, 'eyeing'),\n",
       " (27, 'hope'),\n",
       " (27, 'Nevertheless'),\n",
       " (27, 'looks'),\n",
       " (27, 'overboard'),\n",
       " (27, 'sideways'),\n",
       " (27, 'command'),\n",
       " (27, 'dropped'),\n",
       " (27, 'wholly'),\n",
       " (27, 'born'),\n",
       " (27, 'ahead'),\n",
       " (27, 'alongside'),\n",
       " (27, 'Fedallah'),\n",
       " (26, 'play'),\n",
       " (26, 'received'),\n",
       " (26, 'lie'),\n",
       " (26, 'royal'),\n",
       " (26, 'enormous'),\n",
       " (26, 'island'),\n",
       " (26, 'King'),\n",
       " (26, 'degree'),\n",
       " (26, 'yourself'),\n",
       " (26, 'considerable'),\n",
       " (26, 'circumstances'),\n",
       " (26, 'started'),\n",
       " (26, 'followed'),\n",
       " (26, 'flying'),\n",
       " (26, 'wooden'),\n",
       " (26, 'ears'),\n",
       " (26, 'fancy'),\n",
       " (26, 'Upon'),\n",
       " (26, 'getting'),\n",
       " (26, 'yes'),\n",
       " (26, 'otherwise'),\n",
       " (26, 'giving'),\n",
       " (26, 'circumstance'),\n",
       " (26, 'read'),\n",
       " (26, 'From'),\n",
       " (26, 'bodily'),\n",
       " (26, 'suspended'),\n",
       " (26, 'pointed'),\n",
       " (26, 'blow'),\n",
       " (26, 'blubber'),\n",
       " (26, 'whiteness'),\n",
       " (25, 'yards'),\n",
       " (25, 'learned'),\n",
       " (25, 'masts'),\n",
       " (25, 'carry'),\n",
       " (25, 'thrown'),\n",
       " (25, 'front'),\n",
       " (25, 'year'),\n",
       " (25, 'bit'),\n",
       " (25, 'silent'),\n",
       " (25, 'leaning'),\n",
       " (25, 'seated'),\n",
       " (25, 'believe'),\n",
       " (25, 'stop'),\n",
       " (25, 'thick'),\n",
       " (25, 'hump'),\n",
       " (25, 'cases'),\n",
       " (25, 'number'),\n",
       " (25, 'added'),\n",
       " (25, 'supper'),\n",
       " (25, 'chest'),\n",
       " (25, 'interval'),\n",
       " (25, 'duty'),\n",
       " (25, 'thinking'),\n",
       " (25, 'similar'),\n",
       " (25, 'skull'),\n",
       " (25, 'takes'),\n",
       " (25, 'scene'),\n",
       " (25, 'complete'),\n",
       " (25, 'Thus'),\n",
       " (25, 'woe'),\n",
       " (25, 'bearing'),\n",
       " (25, 'twenty'),\n",
       " (25, 'steady'),\n",
       " (24, 'coat'),\n",
       " (24, 'warm'),\n",
       " (24, 'grow'),\n",
       " (24, 'king'),\n",
       " (24, 'dart'),\n",
       " (24, 'thirty'),\n",
       " (24, 'floating'),\n",
       " (24, 'seldom'),\n",
       " (24, 'love'),\n",
       " (24, 'bright'),\n",
       " (24, 'Dutch'),\n",
       " (24, 'different'),\n",
       " (24, 'regular'),\n",
       " (24, 'pursuit'),\n",
       " (24, 'storm'),\n",
       " (24, 'watery'),\n",
       " (24, 'chief'),\n",
       " (24, 'drop'),\n",
       " (24, 'orders'),\n",
       " (24, 'exactly'),\n",
       " (24, 'perils'),\n",
       " (24, 'became'),\n",
       " (24, 'afterwards'),\n",
       " (24, 'swift'),\n",
       " (24, 'Of'),\n",
       " (24, 'First'),\n",
       " (24, 'ran'),\n",
       " (24, 'aside'),\n",
       " (24, 'escape'),\n",
       " (24, 'friend'),\n",
       " (24, 'hinted'),\n",
       " (24, 'hunters'),\n",
       " (24, 'spread'),\n",
       " (24, 'd'),\n",
       " (24, 'thyself'),\n",
       " (24, 'Stand'),\n",
       " (24, 'remains'),\n",
       " (24, 'keel'),\n",
       " (24, 'oar'),\n",
       " (23, 'country'),\n",
       " (23, 'six'),\n",
       " (23, 'kill'),\n",
       " (23, 'regarded'),\n",
       " (23, 'blows'),\n",
       " (23, 'vessels'),\n",
       " (23, 'honour'),\n",
       " (23, 'answer'),\n",
       " (23, 'following'),\n",
       " (23, 'port'),\n",
       " (23, 'beyond'),\n",
       " (23, 'nevertheless'),\n",
       " (23, 'gods'),\n",
       " (23, 'fiery'),\n",
       " (23, 'midnight'),\n",
       " (23, 'spring'),\n",
       " (23, 'wall'),\n",
       " (23, 'lances'),\n",
       " (23, 'Is'),\n",
       " (23, 'flew'),\n",
       " (23, 'higher'),\n",
       " (23, 'somewhere'),\n",
       " (23, 'hot'),\n",
       " (23, 'hidden'),\n",
       " (23, 'during'),\n",
       " (23, 'wife'),\n",
       " (23, 'cutting'),\n",
       " (23, 'flesh'),\n",
       " (23, 'sweet'),\n",
       " (23, 'instead'),\n",
       " (23, 'beat'),\n",
       " (23, 'rose'),\n",
       " (23, 'chapter'),\n",
       " (23, 'finally'),\n",
       " (23, 'hence'),\n",
       " (23, 'lad'),\n",
       " (23, 'speaking'),\n",
       " (23, 'circle'),\n",
       " (23, 'strength'),\n",
       " (23, 'remain'),\n",
       " (23, 'secret'),\n",
       " (23, 'hunt'),\n",
       " (23, 'level'),\n",
       " (23, 'Lakeman'),\n",
       " (22, 'Like'),\n",
       " (22, 'battle'),\n",
       " (22, 'forty'),\n",
       " (22, 'answered'),\n",
       " (22, 'stove'),\n",
       " (22, 'lives'),\n",
       " (22, 'rear'),\n",
       " (22, 'drawn'),\n",
       " (22, 'tall'),\n",
       " (22, 'wonderful'),\n",
       " (22, 'centre'),\n",
       " (22, 'filled'),\n",
       " (22, 'shipmates'),\n",
       " (22, 'hole'),\n",
       " (22, 'cause'),\n",
       " (22, 'game'),\n",
       " (22, 'real'),\n",
       " (22, 'owing'),\n",
       " (22, 'alive'),\n",
       " (22, 'drew'),\n",
       " (22, 'commanded'),\n",
       " (22, 'deadly'),\n",
       " (22, 'hint'),\n",
       " (22, 'descried'),\n",
       " (22, 'souls'),\n",
       " (22, 'Nantucketer'),\n",
       " (22, 'windward'),\n",
       " (22, 'shark'),\n",
       " (22, 'dashed'),\n",
       " (22, 'fin'),\n",
       " (22, 'pulling'),\n",
       " (22, 'Radney'),\n",
       " (21, 'shore'),\n",
       " (21, 'TO'),\n",
       " (21, 'ca'),\n",
       " (21, 'magnitude'),\n",
       " (21, 'My'),\n",
       " (21, 'striking'),\n",
       " (21, 'These'),\n",
       " (21, 'bound'),\n",
       " (21, 'decks'),\n",
       " (21, 'formed'),\n",
       " (21, 'original'),\n",
       " (21, 'Ha'),\n",
       " (21, 'negro'),\n",
       " (21, 'spot'),\n",
       " (21, 'worse'),\n",
       " (21, 'talk'),\n",
       " (21, 'hair'),\n",
       " (21, 'minutes'),\n",
       " (21, 'spare'),\n",
       " (21, 'break'),\n",
       " (21, 'terrible'),\n",
       " (21, 'passing'),\n",
       " (21, 'quickly'),\n",
       " (21, 'burst'),\n",
       " (21, 'lofty'),\n",
       " (21, 'age'),\n",
       " (21, 'prow'),\n",
       " (21, 'lord'),\n",
       " (21, 'hailed'),\n",
       " (21, 'invested'),\n",
       " (21, 'gazing'),\n",
       " (21, 'advance'),\n",
       " (21, 'evinced'),\n",
       " (21, 'beheld'),\n",
       " (21, 'gunwale'),\n",
       " (20, 'Gabriel'),\n",
       " (20, 'besides'),\n",
       " (20, 'former'),\n",
       " (20, 'swim'),\n",
       " (20, 'master'),\n",
       " (20, 'swam'),\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df = df[df[\"token\"].str.isalpha()]\n",
    "def answer_six():\n",
    "    new_df = words_df[words_df[\"frequency\"] > 2000]\n",
    "    result = list(zip(words_df.frequency, words_df.token))\n",
    "    \n",
    "    \n",
    "    return result\n",
    "answer_six()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13715, 'the'),\n",
       " (6513, 'of'),\n",
       " (6010, 'and'),\n",
       " (4545, 'a'),\n",
       " (4515, 'to'),\n",
       " (3908, 'in'),\n",
       " (2978, 'that'),\n",
       " (2459, 'his'),\n",
       " (2196, 'it'),\n",
       " (2097, 'I')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_six():\n",
    "    import operator\n",
    "    return sorted([(freq, token) for token, freq in text1.vocab().items() if freq > 2000 and token.isalpha()], key=operator.itemgetter(0), reverse=True)\n",
    "answer_six()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "What is the average number of tokens per sentence?\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.881952902963864"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "def answer_seven():\n",
    "    sentences = sent_tokenize(moby_raw)\n",
    "    words = [len(word_tokenize(sentence)) for sentence in sentences]\n",
    "    result = sum(words) / float(len(sentences))\n",
    "    \n",
    "    return result\n",
    "\n",
    "answer_seven()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "What are the 5 most frequent parts of speech in this text? What is their frequency?\n",
    "\n",
    "*This function should return a list of tuples of the form `(part_of_speech, frequency)` sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('NN', 3944), ('JJ', 2958), ('NNP', 2950), ('NNS', 2420), ('VBG', 1402)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "def answer_eight():\n",
    "    tags = nltk.pos_tag(words_df.token)\n",
    "    frequencies = FreqDist([tag for (word, tag) in tags])\n",
    "    result = frequencies.most_common(5)\n",
    "    \n",
    "    return result\n",
    "\n",
    "answer_eight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 32730), ('IN', 28657), ('DT', 25867), (',', 19204), ('JJ', 17620)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_eight():\n",
    "    from collections import Counter\n",
    "    import operator\n",
    "    return sorted(Counter([tag for token, tag in nltk.pos_tag(text1)]).items(), key=operator.itemgetter(1), reverse=True)[:5]\n",
    "answer_eight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Spelling Recommender\n",
    "\n",
    "For this part of the assignment you will create three different spelling recommenders, that each take a list of misspelled words and recommends a correctly spelled word for every word in the list.\n",
    "\n",
    "For every misspelled word, the recommender should find find the word in `correct_spellings` that has the shortest distance*, and starts with the same letter as the misspelled word, and return that word as a recommendation.\n",
    "\n",
    "*Each of the three different recommenders will use a different distance measure (outlined below).\n",
    "\n",
    "Each of the recommenders should provide recommendations for the three default words provided: `['cormulent', 'incendenece', 'validrate']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"words\")\n",
    "from nltk.corpus import words\n",
    "\n",
    "correct_spellings = words.words()\n",
    "spellings_series = pd.Series(correct_spellings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the trigrams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpulent', 'indecence', 'validate']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_nine(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    result = []\n",
    "    import operator\n",
    "    for entry in entries:\n",
    "        spell_list = [spell for spell in correct_spellings if spell.startswith(entry[0]) and len(spell) > 2]\n",
    "        distance_list = [(spell, nltk.jaccard_distance(set(nltk.ngrams(entry, n=3)), set(nltk.ngrams(spell, n=3)))) for spell in spell_list]\n",
    "        result.append(sorted(distance_list, key=operator.itemgetter(1))[0][0])\n",
    "    \n",
    "    \n",
    "    return result\n",
    "answer_nine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the 4-grams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cormus', 'incendiary', 'valid']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_ten(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    result = []\n",
    "    import operator\n",
    "    for entry in entries:\n",
    "        spell_list = [spell for spell in correct_spellings if spell.startswith(entry[0]) and len(spell) > 2]\n",
    "        distance_list = [(spell, nltk.jaccard_distance(set(nltk.ngrams(entry, n=4)), set(nltk.ngrams(spell, n=4)))) for spell in spell_list]\n",
    "        result.append(sorted(distance_list, key=operator.itemgetter(1))[0][0])\n",
    "    return result\n",
    "    \n",
    "answer_ten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Edit distance on the two words with transpositions.](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance)**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpulent', 'intendence', 'validate']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_eleven(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    result = []\n",
    "    import operator\n",
    "    for entry in entries:\n",
    "        spell_list = [spell for spell in correct_spellings if spell.startswith(entry[0]) and len(spell) >2]\n",
    "        distance_list = [(spell, nltk.edit_distance(entry, spell, transpositions=True)) for spell in spell_list]\n",
    "        result.append(sorted(distance_list, key=operator.itemgetter(1))[0][0])\n",
    "    \n",
    "    return result\n",
    "    \n",
    "answer_eleven()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "r35En",
   "launcher_item_id": "tCVfW",
   "part_id": "NTVgL"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
